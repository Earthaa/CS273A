{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font size = 5><b><i>Assignment3</i></b></font></center>\n",
    "<div style=\"text-align: right\"><i>By Yi Zhou</i></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106623a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mltools as ml\n",
    "import matplotlib.pyplot as plt   # use matplotlib for plotting with inline plots\n",
    "%matplotlib inline\n",
    "plt.set_cmap('jet');\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # for deprecated matplotlib functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = np.genfromtxt(\"data/iris.txt\",delimiter=None)\n",
    "X, Y = iris[:,0:2], iris[:,-1]   # get first two features & target\n",
    "X,Y  = ml.shuffleData(X,Y)       # reorder randomly rather than by class label\n",
    "X,_  = ml.transforms.rescale(X)  # rescale to improve numerical stability, speed convergence\n",
    "\n",
    "XA, YA = X[Y<2,:], Y[Y<2]        # Dataset A: class 0 vs class 1\n",
    "XB, YB = X[Y>0,:], Y[Y>0]        # Dataset B: class 1 vs class 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myPlotBoundary(self, X,Y):\n",
    "    \"\"\" Plot the (linear) decision boundary of the classifier, along with data \"\"\"\n",
    "    if len(self.theta) != 3: raise ValueError('Data & model must be 2D');\n",
    "    ax = X.min(0),X.max(0); ax = (ax[0][0],ax[1][0],ax[0][1],ax[1][1]);\n",
    "    ## TODO: find points on decision boundary defined by theta0 + theta1 X1 + theta2 X2 == 0\n",
    "    x1b = np.array([ax[0],ax[1]]);  # at X1 = points in x1b\n",
    "    x2b = NotImplementedError;      # TODO find x2 values as a function of x1's values\n",
    "    ## Now plot the data and the resulting boundary:\n",
    "    A = Y==self.classes[0]; # and plot it:\n",
    "    plt.plot(X[A,0],X[A,1],'b.',X[-A,0],X[-A,1],'r.',x1b,x2b,'k-'); plt.axis(ax); plt.draw();\n",
    "\n",
    "\n",
    "# Create a shell classifier\n",
    "class logisticClassify2(ml.classifier):\n",
    "    classes = []\n",
    "    theta = np.array( [-1, 0, 0] )   # initialize theta to something\n",
    "    plotBoundary = myPlotBoundary    # \n",
    "    predict = None                   # these functions will be implemented later\n",
    "    train = None\n",
    "\n",
    "learnerA = logisticClassify2()\n",
    "learnerA.classes = np.unique(YA)       # store the class values for this problem\n",
    "learnerA.theta = NotImplementedError;  # TODO: insert hard-coded values\n",
    "learnerA.plotBoundary(learnerA,XA,YA)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Should go in your logistic2 class:\n",
    "def myPredict(self,X):\n",
    "    \"\"\" Return the predictied class of each data point in X\"\"\"\n",
    "    raise NotImplementedError\n",
    "    ## TODO: compute linear response r[i] = theta0 + theta1 X[i,1] + theta2 X[i,2]  for each i\n",
    "    ## TODO: if z[i] > 0, predict class 1:  Yhat[i] = self.classes[1]\n",
    "    ##       else predict class 0:  Yhat[i] = self.classes[0]\n",
    "    return Yhat\n",
    "\n",
    "\n",
    "# Update our shell classifier definition\n",
    "class logisticClassify2(ml.classifier):\n",
    "    classes = []\n",
    "    theta = np.array( [-1, 0, 0] )   # initialize theta to something\n",
    "    plotBoundary = myPlotBoundary    # \n",
    "    predict = myPredict              \n",
    "    train = None\n",
    "\n",
    "learnerA = logisticClassify2()\n",
    "learnerA.classes = np.unique(YA)       # store the class values for this problem\n",
    "learnerA.theta = NotImplementedError;  # TODO: insert hard-coded values\n",
    "\n",
    "print \"Error: \", learnerA.err(XA,YA)\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If predict is implemented, then the inherited 2D visualization function should work; you can verify your decision boundary from P1.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml.plotClassify2D(learnerA,XA,YA)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...\n",
    "\n",
    "\n",
    "Here is an example of latex equations that may be useful for expressing the gradient:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Gradient of NLL\n",
    "\n",
    "Our negative log-likelihood loss is:\n",
    "$$J_j(\\theta) = - \\begin{cases} \\log( \\sigma(x^{(i)} \\cdot \\theta)) & \\mbox{if}\\  y^{(i)}=1 \\\\ \\log(1-\\sigma(x^{(i)} \\cdot \\theta)) & \\mbox{if}\\  y^{(i)}=0 \\end{cases}$$\n",
    "\n",
    "Thus, its gradient is:\n",
    "$$\\nabla J_j(\\theta) = (something)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6\n",
    "\n",
    "Now define the train function and complete its missing code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myTrain(self, X, Y, initStep=1.0, stopTol=1e-4, stopEpochs=5000, plot=None):\n",
    "    \"\"\" Train the logistic regression using stochastic gradient descent \"\"\"\n",
    "    M,N = X.shape;                     # initialize the model if necessary:\n",
    "    self.classes = np.unique(Y);       # Y may have two classes, any values\n",
    "    XX = np.hstack((np.ones((M,1)),X)) # XX is X, but with an extra column of ones\n",
    "    YY = ml.toIndex(Y,self.classes);   # YY is Y, but with canonical values 0 or 1\n",
    "    if len(self.theta)!=N+1: self.theta=np.random.rand(N+1);\n",
    "    # init loop variables:\n",
    "    epoch=0; done=False; Jnll=[]; J01=[];\n",
    "    while not done:\n",
    "        stepsize, epoch = initStep*2.0/(2.0+epoch), epoch+1; # update stepsize\n",
    "        # Do an SGD pass through the entire data set:\n",
    "        for i in np.random.permutation(M):\n",
    "            ri    = NotImplementedError;     # TODO: compute linear response r(x)\n",
    "            gradi = NotImplementedError;     # TODO: compute gradient of NLL loss\n",
    "            self.theta -= stepsize * gradi;  # take a gradient step\n",
    "\n",
    "        J01.append( self.err(X,Y) )  # evaluate the current error rate\n",
    "\n",
    "        ## TODO: compute surrogate loss (logistic negative log-likelihood)\n",
    "        ##  Jsur = sum_i [ (log si) if yi==1 else (log(1-si)) ]\n",
    "        Jnll.append( NotImplementedError ) # TODO evaluate the current NLL loss\n",
    "        plt.figure(1); plt.plot(Jnll,'b-',J01,'r-'); plt.draw();    # plot losses\n",
    "        if N==2: plt.figure(2); self.plotBoundary(X,Y); plt.draw(); # & predictor if 2D\n",
    "        plt.pause(.01);                    # let OS draw the plot\n",
    "        \n",
    "\n",
    "        ## For debugging: you may want to print current parameters & losses\n",
    "        # print self.theta, ' => ', Jnll[-1], ' / ', J01[-1]\n",
    "        # raw_input()   # pause for keystroke\n",
    "\n",
    "        # TODO check stopping criteria: exit if exceeded # of epochs ( > stopEpochs)\n",
    "        done = NotImplementedError;   # or if Jnll not changing between epochs ( < stopTol )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update our shell classifier definition\n",
    "class logisticClassify2(ml.classifier):\n",
    "    classes = []\n",
    "    theta = np.array( [-1, 0, 0] )   # initialize theta to something\n",
    "    plotBoundary = myPlotBoundary    # \n",
    "    predict = myPredict              # Now all parts are implemented\n",
    "    train = myTrain\n",
    "\n",
    "learnerA = logisticClassify2()\n",
    "learnerA.theta = np.array([0.,0.,0.]);\n",
    "learnerA.train(XA,YA,initStep=1e-1,stopEpochs=1000,stopTol=1e-5);\n",
    "\n",
    "ml.plotClassify2D(learnerA,XA,YA)\n",
    "print(\"Training error rate: \",learnerA.err(XA,YA))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ... ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
